\subsection{How to measure similarity among items?}
\label{sec:llr}

In the last section (\ref{sec:problem}) we use a matrix $M$ that contains similarity strength among items. This section describes how $M$ is computed.

In order to compute the similarity between two items we count the \gls{coocc} among two items with respect to a particular user action and then compute the the \gls{llr} ratio of that \gls{coocc}.

\subsubsection{Co-occurence}
\label{sec:cooccurence}

Co-occurence in the context of a recommender system is the number of times a pair of items appear together in some user's action history. For instance, if there are 5 users who all liked items $A$ and $B$ then $A$ and $B$ co-occur 5 times. Coocurrence indicates similarity. The more two items turn up togheter, the more related they probably are. We can count the \gls{coocc} of items with respect to any action or entity. For instance, we can count how many times two items are associated with the same tag or purchased by the same users.

\subsubsection{Log-likelihood ratio}
\label{sec:llrs}

\gls{llr} is a probabilistic measure of the importance of a \gls{coocc}. The \gls{llr} similarity  is the probability that two users share the same items because the items are similar and not due to chance. It finds important \gls{coocc} and filters out the coincidental. Hence it avoids that the result is skewed against popular items \cite{Dunning93}. Compared to the Jaccard coefficient \cite{Hartung} the log-likelihood-based similarity computes higher similarites for anomalous co-occurences than for items that occur in every user history. For a detailed explanation of the math involved see appendix and \cite{Dunning93}. 

According to \cite{Dunning14} using the \gls{llr} ratio of the \gls{coocc} has several advantages.
\begin{itemize}
\item It yields good results for data that only captures the interaction and no \glspl{preference} \cite{Dunning93}.
\item The similarity is not skewed against popular items.
\item We can use distributed MapReduce based algorithms to compute the \glspl{coocc}. Hence the computation of the \gls{llr} similarity is \gls{scalable}.
\end{itemize}

\begin{figure}
\centering
\begin{tikzpicture}[node distance=40mm,
data/.style={
rectangle,
draw,
thin,
minimum height=3.5em
},
to/.style={->,>=stealth',shorten >=1pt,semithick,font=\footnotesize},
]
\node (hist) [data, align=left] {User actions\\history};
\node (co) [data,right of=hist,align=left] {Co-occurence};
\node (in) [data,right of=co,align=left] {LLR\\indicator\\matrix};
\draw[to] (hist) -- (co);
\draw[to] (co) -- (in);
\end{tikzpicture}
\caption{To compute the indicator matrix {\ttfamily spark-itemsimilarity} computes the co-occurence  of user actions and then compute the indicator matrix with the log-likelihood strengths.}
\label{fig:llrworkflow}
\end{figure}

\subsubsection{Example}
\label{sec:llrexample}

We describe the log-likelihood based similarity with a small example dataset. Suppose we analyse the user action history for the action ``like'' given in table \ref{tbl:llr1}. 
Table \ref{tbl:llr1} shows the likes of four users for five items. The items are represented with ids 1-4 and the users with ids 101 - 104  (see appendix listing \ref{lst:sampledata} for raw web log).
In the example dataset of table \ref{tbl:llr1} the items 1 and 2 are similar because three users liked both of them.

We compute the \gls{indicatorm} in two steps as shown in figure \ref{fig:llrworkflow}.
\begin{enumerate}
\item Count \glspl{coocc}
\item Compute \gls{llr} of \glspl{coocc}
\end{enumerate}

\begin{table}
\begin{center}
\begin{tabular}{rllll}
 & 101 & 102 & 103 & 104\\
1 & x & x & x &  \\
2 & x &   & x & x\\
3 & x & x & x &  \\
4 &   & x & x & x\\
5 & x & x & x & x\\
\end{tabular}
\end{center}
\caption{Example dataset. The columns represent the user interaction with an item. Items are named 1 - 4 and users 101 - 104}
\label{tbl:llr1}
\end{table}

In order to get the similarities between all items we count the \gls{coocc} of ``\glspl{like}'' for all item pairs. This leads to the $5 \times 5$ \gls{indicatorm} $C$ shown in equation \ref{eq:coocm}. The rows and the columns are items. $C$ is a similarity comparison of every row of table \ref{tbl:llr1} to every other row.

\begin{equation}
  \label{eq:coocm}
C =\bordermatrix{~ & 1 & 2 & 3 & 4 & 5 \cr
1 & 4 & 2 & 3 & 2 & 3 \cr
2 & 2 & 3 & 2 & 1 & 3 \cr
3 & 3 & 2 & 3 & 2 & 3 \cr
4 & 2 & 1 & 2 & 3 & 3 \cr
5 & 3 & 3 & 3 & 3 & 4 \cr}
\end{equation}

In the next step we compute the \gls{llr} ratio strength of the \glspl{coocc} for every item pair. This will again produce a $5 \times 5$ \gls{indicatorm}. Equation \ref{eq:coocm1} shows the \gls{indicatorm} for the sample dataset from table \ref{tbl:llr1}.

\begin{equation}
  \label{eq:coocm1}
L =\bordermatrix{~ & 1 & 2 & 3 & 4 & 5 \cr
1 &   & 0.40 & 0.81 & 0.63 & 0 \cr
2 & 0.40 &  & 0.40 & 0.63 & 0 \cr
3 & 0.81 & 0.40 &  & 0.63 & 0 \cr
4 & 0.63 & 0.63 & 0.63 &  & 0 \cr
5 & 0 & 0 & 0 & 0 & \cr
}
\end{equation}

Allthoug item 5 shares all users with item 1 and 3, the log-likelihood ratio is 0 because every user purchased item 5. The goal of collaborative filtering is to show the user items he would not find by himself. Item 5 is popular and a user will probably discover it by looking up a list of items sorted by popularity (this is a form of non-personalized recommendation). Hence Item 5 is not a valuable personal recommendation because we could extract it without a recommender. For this reason the \gls{llr} is suitable similarity metric for a recommender engine.

\subsubsection{Log-likelihood similarity implementation}
\label{sec:llrimpl}

Apache Mahout provides an implemenation of log-likelihood similarity with the class \verb|LogLikelihoodSimilarity|. Unfortunatly the \verb|LogLikelihoodSimilarity| is a non-distributed implementation. It would take too long to calculate the indicator matrix for a dataset with over 10 million items and we would have difficulties to load all data into the memory. 

The computation of the \gls{coocc} of every item pair can be distributed and run in parallel by applying the MapReduce programming model as follows:
\begin{description}
\item[Map] Determine all \glspl{coocc} for one user's history and yield a pair of items for each \gls{coocc}
\item[Reduce] For each item collect all corresponding item pair of the map phase and count all \glspl{coocc} and yield a vector with all items and the corresponding \gls{coocc}.
\end{description}
\todo{bild map reduce einfuegen}

This task can run in parallel on different nodes on a cluster computer framework, such as Apache Spark. Hence the computation of the \gls{indicatorm} is \gls{scalable}.
In order to compute the \gls{llr} similarity distributed on a Spark cluster, Apache Mahout provides the \verb|spark-itemsimilarity| job. 
\verb|spark-itemsimilarity| is a command line job and we can start it from the mahout shell.
\begin{verbatim}
./mahout spark-itemsimilarity --input $infile --output $outfile
\end{verbatim}
The job connects to the Spark cluster instance defined by the environment variable $MASTER$ and computes the \gls{indicatorm} in parallel. With the \verb|spark-itemsimilarity| job the indicator matrix can be computed in $O(n)$ \cite{Schelter}. 
The input text file has to be in the following format:
\begin{verbatim}
userID, action, itemID
\end{verbatim}
\verb|spark-itemsimilarity| will output an indicator matrix created by collecting and counting all \glspl{coocc} and calculating the \gls{llr} ratio strenght. The output will be a text file that represents the indicator matrix as sparse vectors for every item. For every item we get the similarities to all other items.
\begin{verbatim}
itemID1<tab>itemID2:similarityvalue<space>itemID3:similarityvalue
\end{verbatim}

In our demo application we have written a python script to fetch the data from the sqlite3 database and transform to the Spark input format.
The co-occurence based recommender uses the user behavior log in order to compute a similarity model. 

\begin{figure}
\centering
\begin{tikzpicture}[node distance=40mm,
data/.style={
rectangle,
draw,
thin,
minimum height=3.5em
},
to/.style={->,>=stealth',shorten >=1pt,semithick,font=\footnotesize},
]
\node (log) [data, align=left] {User actions\\log file};
\node (spark) [data,right of=log,align=left] {Apache Spark\\LLR job};
\node (model) [data,right of=spark,align=left] {Similarity\\model};
\draw[to] (log) -- (spark);
\draw[to] (spark) -- (model);
\end{tikzpicture}
\caption{The {\ttfamily spark-itemsimilarity} job of Apache Spark computes the LLR similarity based on the user behavior log file.}
\end{figure}
