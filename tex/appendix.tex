\section{Tools, libraries and frameworks}

The following software was used to build the evaluator, the search engine update job and the web application.
\begin{itemize}
\item JVM 1.8.45 OpenJDK. Solr, Spark and Play run on the JVM.
\item Scala Compiler 2.11.7. The web application is written in Scala.
\item Maven Java build tool. Maven was used to build Spark and evaluator and the search engine. version 3.19
\item Solr version 4.7.2
\item Spark version 1.4.0
\item Play version 2.4. We used the Play framework because it runs on the JVM and we can use the Solr Client Library in the Webserver.
\item AngularJS. Javascript Framework. Used for WebGUI.
\item Mahout 0.9 
\item sqlite3 3.8.7.4 We use sqlite3 because there are JDBC driver and a python interface.
\item python 2.7.9. Python is used to transform the date from sqlite3 to the input format of Apache Spark.
\end{itemize}

\section{Source code listings}
\label{sec:listings}

\begin{lstlisting}[caption={To simulate the user action ``like'' we extract all ratings equal or above a score of 4.0 and use the result as training set},label={lst:pref2like}]
 public GenericBooleanPrefDataModel pref2like(DataModel dataModel,
	float threshold) {
	try {
	FastByIDMap<FastIDSet> userlikes = new FastByIDMap<FastIDSet>(
					dataModel.getNumUsers());
	LongPrimitiveIterator iter = dataModel.getUserIDs();
	while (iter.hasNext()) {
          long userid = iter.nextLong();
          PreferenceArray prefs = dataModel
		.getPreferencesFromUser(userid);
          FastIDSet ids = new FastIDSet(prefs.length());
          for (Preference p : prefs) {
		if (p.getValue() >= threshold) {
                  ids.add(p.getItemID());
			}
		}
	userlikes.put(userid, ids);
	}
    return new GenericBooleanPrefDataModel(userlikes);
\end{lstlisting}


\section{Apache Solr}
\label{sec:solr}

Apache Solr is a search engine that is optimized to search large volumes of text-centric data and return results sorted by relevance. It is built on Apache Lucene, an information retrieval library \cite{grainger}. Solr stores the documents in a flat structure and we can search for terms in the documents. It provides a HTTP API for all interactions, like quering, updating e.t.c.

The reason why we deploy a search engine in order to make recommendations is that Solr scores documents based on the presence of query terms in the document similar to a recommendations engine based on the presence of indicator.

Another reason why we deploy a search engine is that the application is read-dominant. The recommender will query the data far more often than it will create new documents or update the indicators. Solr is optimized to for executing queries as opposed to storing data.

\section{Apache Mahout}
\label{sec:mahout}

Apache mahout is a top-level Apache project that provide implementations of collaborative filtering algorithms among other machine learning techniques. The development began in 2008 \cite{Owen}. It provides server Apache Spark jobs in order to process large amount of data. We used it because it's Spark support and because it's well documented.
Mahout provides a large set of recommender algorithms. And it is easy to evaluate and compare several algorithms on a specific dataset.

\subsection{Data representation}
\label{sec:datarepresentation}

Apache Mahout uses it's own data structures to store and access preference data. Mahout provides it's own map implementation \verb|FastByIDMap|. Keys in \verb|FastByIDMap| are long primitives instead of java objects. In addition \verb|FastByIDMap| has no additional \verb|Map.Entry| object per entry. The avoidance of java object saves memory. Depending on the implementation of the JVM a java object allocates about 28 bytes of memory. \verb|FastByIDMap| consumes about 28 bytes per entry, compared to about 84 byte per entry for \verb|HashMap| from \verb|java.util|.

\section{Log-likelihood ratio}
\label{sec:llrratio}
The log-likelihood metric quantifies the propability of how
unlikely it is that two items interact with the same users is due to chance. The less likely, the more similar we are.
In order to compute the \gls{llr} ratio of the \gls{coocc} among item $A$ and item $B$ we have to count how many users interacted both with $A$ and $B$, how many users interacted with $A$ without interacting with $B$, how many users interacted with $B$ without interacting with $A$ and how many user interacted with none of them.

 \todo{llr contency table einfuegen und formel fuer llr}

\section{Infrastructur}
\label{sec:infrastructur}

\subsection{Webapplication}
\label{sec:web}

To start the Webapplication run:
\begin{verbatim}
sbt build 
\end{verbatim}
This assumes that the scala build tool (sbt) is installed.
\subsection{Apache Spark}
\label{sec:spark}
Apache Spark is a cluster computer framewor. It allows user programs to load data into a cluster's memory. It is well suited to machine learning algorithms \cite{Karau}.
\subsubsection{How to deploy Spark}
\label{sec:sparkdeploy}

To run \verb|spark-itemsimilarity| we have to deploy Apache Spark and and start it in standalone mode with the script \verb|start-master.sh|. Once startet the script will print a URL which we can pass the \verb|spark-itemsimilarity| job as ``master'' argument and the job can connect to the cluster. 

\section{Sample Input Data}
\label{sec:sampleinput}

\begin{lstlisting}[label=lst:sampledata]
itemid, userid, timestamp
1,101,980730861
1,102,980731380
1,103,980731926
2,101,980732037
2,103,980730408
2,104,980731766
3,101,980731282
3,102,980730769
3,103,980731208
4,102,980732235
4,103,980731417
5,101,980731745
5,102,980731621
5,103,980731417
5,104,980731208  
\end{lstlisting}

