\section{Conclusion}
\label{sec:conclusion}

We have built a prototype of a \gls{multimodal} \gls{rec} with a search engine according to the suggestions of \cite{Dunning14}. 
This approach simplifies the development process and lowers the entry barrier for developer without a strong mathematical background because we do not have to make descisions which algorithms or similarity metrics to choose. 

User interaction is the best clue what users want.
The design allows to use a variety of user interactions and metadata as input data. This hybrid approach improves the performance of the \gls{topnt}. Multiple \glspl{indicator} are stored in distinct field within Solr. The recommender engine can be extended with additional \glspl{indicator}.


The calculation of \gls{coocc} indicator matrix and therefore the update process of the search engine is computational expensive. Mahout's \verb|spark-itemsimilarity| job allows us to compute \gls{indicatorm} at scale.
The two part design of the \gls{rec} allows us to do the heavy lifting upfront. In return the \gls{topnt} is performed blazingly fast because Apache Solr is optimized for text retrieval queries. 

A large amount of work was required to convert formats between the user history database, the Apache Mahout and Apache Solr. 

The proposed design did not described the inclusion of item similarity values in the search engine. We used the payload mechanism of Apache Lucene to weight indicator with the corresponding similatity value.

Unfortunatly \cite{Dunning14} does not descibe an evaluation method for the proposed design. We evaluated the recommnender with the accuracy metrics precision and recall. The usefulness of these metrics depends on the definition of relevant items. We defined items that the user has given a high rating as relevant. The evaluation method used in this report penalizes items that the user never has rated or even seen. 

Another problem with precision and recall emerges when the preferences are Boolaen data, like in the demo application, because we can not pick the $N$ best rated items and have to select them at random. For this reason we used the MovieLens data set that contains preference values and simulated user actions.

The evaluation results of the co-occurence based recommender are not overwhelming. Compared to the \gls{itembased} recommender the increase of quality is small. But the evaluation method only considers items that the users already liked as relevant. We do not know how usefull a recommendation for an individual user is. It could be that the co-occurence based recommender is suggesting items that the user never has seen and that are desirable for the user.

The system may be improved throug the use of 
\begin{description}
\item[Dithering] 
\item[Anti-flood] 
\item[Cross-coooccurence]
\end{description}
dithering.

